# Memorandum on LLaMA2 Fine-Tune

## Introduction

Memo, short for something to be remembered. How do I call upon my muses to write something inspiring for the times... on something as mundane as fine-tuning a language model...

TOUGH QUESTION?

I'm reading reading *"Competing in the Age of AI"* for some long-term predictive insight

using this insight, i will be able to write a better memo

How does our company flourish in the age of AI?

no field will remain untouched by AI

universal engine of execution

leverage the work done by AI, who work in realtime in their runtime.

AI woven into the fabric of the firm

Increasing levels of digitization, analytics, and AI/ML can dramatically improve the scalability of a business

build a company based on AI/ML foundations

full potential opportunities and challenges

"build upon existing expertise"

“target new processes to digitize and enable, through analytics and AI”

different kind of company - 

“changing the way it gathers and uses data, reacts to information, makes operating decisions, and executes operating tasks.”

“AI for strategy and leadership”

---

business model - creates and captures value
operating model - delivers value

---




How to be a competitive company in the age of AI.
landscape of business + nature of companies


Memo, short for something to be remembered.

How is this more important than anything else that needs to be remembered.

This is a fine-tune of the LLaMA2 model on a dataset of interview questions. The goal is to create a model that can generate interview answers given a question.

## Setup Instructions (Guide)

### Data Generation

one thing to note is that one can use GPT4 or other LLMs to generate synthetic data. This is a good way to generate a lot of data for fine-tuning. The intuition here is that data modeling and structuring the data is important if one wants to leverage existing training pipelines.

### Training Run
The executable code is in a colab notebook located in this repo.
1) run training set

### Analysis | Benchmarking
## Details

## Benchmarking

## Analysis

Long term thinking about the world of AI and intelligence

Artificial Intelligence in the age of AI


---

How does this relate to the current business context

<>
landscape of business
nature of companies
<>
Balance Hype/Anxiety
promised benefits
potential disruptions - job loss, company failure, fragmentation of society

AI competition
  - scale faster
  - innovate faster
  - personalize better

AI, analytics, networks
 + automation

strategy + operating model

AI first
digital foundation

rag workflow - as advanced prompt engineering

techniques to stuff the context with as much useful information as possible as it makes token prediction


making money in the AGI space
finding a good life
finding a good community
making things feel good
good vibes

---

love
career
life

sunny
autumn

personally i can not pursue them both

i can only choose to pursue one thing
we can contemplate and plan things out in the long term
as far as our predictive capabilities

the other path is something that not many have done
it looks more promising because i can beak new ground
but all the same people have done it, just not currently

the road is equally as i contemplate them
not one step has been taken yet
go and take one way
but it be a decision that can't be taken back

this will be remembered
i will tell of this story
i will take the decision that is less traveled
that will make things interesting

---


Purpose & Meaning - When training an LLM, having a clear purpose and measurable metrics of success are important. 

What specific skills do you want the model to acquire?

How will you evaluate if training is effective?

Aligning training objectives with end goals gives meaning and direction.

Making History - Training a state-of-the-art LLM like LLaMA2 provides an opportunity to push boundaries in AI. The insights from analyzing model behavior during training could open new frontiers in understanding language and reasoning.


Community - Leveraging public datasets, codebases and the broader AI community support during training is key

Feedback from collaborators helps shape the model positively.

Training in isolation risks blindspots.

Fulfillment - While impressive benchmarks motivate, fulfillment comes from enjoying the journey of inquiry and discovery in training. The creative process of designing prompts, datasets and experiments can be profoundly fulfilling.

Present Moment - Being fully present and mindful while training focuses one's attention on model patterns as they emerge. Rushing training risks missing key insights revealed in each iteration. Patience and presence enable learning.