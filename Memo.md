# LLaMA2 Fine-Tune

## Introduction

This is a fine-tune of the LLaMA2 model on a dataset of interview questions. The goal is to create a model that can generate interview answers given a question.

## Setup Instructions (Guide)

### Data Generation

one thing to note is that one can use GPT4 or other LLMs to generate synthetic data. This is a good way to generate a lot of data for fine-tuning. The intuition here is that data modeling and structuring the data is important if one wants to leverage existing training pipelines.

### Training Run
The executable code is in a colab notebook located in this repo.
1) run training set

### Analysis | Benchmarking
## Details

## Benchmarking

## Analysis